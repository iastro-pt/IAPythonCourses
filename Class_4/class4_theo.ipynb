{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python387jvsc74a57bd0fb347f9af4bf6163c7614b75d55774a7b24e9b50914390cba35ad68b1e6aa2bf",
   "display_name": "Python 3.8.7 64-bit ('env')"
  },
  "metadata": {
   "interpreter": {
    "hash": "fb347f9af4bf6163c7614b75d55774a7b24e9b50914390cba35ad68b1e6aa2bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "---\n",
    "# Python Course - Class 4:\n",
    "# Advanced Python and multiprocessing\n",
    "\n",
    "## Contents:\n",
    "\n",
    "- Sets\n",
    "- In-depth functions & related tools \n",
    "- Handling the operating system\n",
    "- Parallel computation\n",
    "\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Sets\n",
    "\n",
    "- Sets can be thought of as a special list that does not allow repeated entries\n",
    "- We can do multiple operations to compare the elements that are whitin the sets\n",
    "- The  items are unordered and unchangeable"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{1, 2, 3, 4}\n"
     ]
    }
   ],
   "source": [
    "# When creating a new set we can either create an empty one:\n",
    "foo = set()\n",
    "\n",
    "# With some pre-determined elements:\n",
    "foo = {1, 2, 3, 4}\n",
    "\n",
    "# or from a previous list/tuple\n",
    "foo = set((1,2,3,4, 1))\n",
    "print(foo)"
   ]
  },
  {
   "source": [
    "## Adding data to a set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{2, (2, 1), (2, 2), 'bar', None}\n"
     ]
    }
   ],
   "source": [
    "foo = set() \n",
    "\n",
    "foo.add(2)\n",
    "foo.add((2,2))\n",
    "foo.add((2,1))\n",
    "foo.add((2,2))\n",
    "foo.add('bar')\n",
    "foo.add(2)\n",
    "foo.add(None)\n",
    "print(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "# We can also use \"comprehensions\" to create a set\n",
    "\n",
    "bar = {i for i in range(10)} \n",
    "\n",
    "print(bar)"
   ]
  },
  {
   "source": [
    "## Removing data from the set\n",
    "\n",
    "We can remove data using either:\n",
    "- remove\n",
    "- discard\n",
    "\n",
    "The first option will raise an error if the element does not exist in the set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{1, 4}\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "3",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-37-8e1fac550b96>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0mfoo\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdiscard\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0mfoo\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mremove\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m: 3"
     ]
    }
   ],
   "source": [
    "foo = {1,2,4}\n",
    "\n",
    "foo.discard(2)\n",
    "print(foo)\n",
    "\n",
    "foo.discard(3)\n",
    "foo.remove(3)"
   ]
  },
  {
   "source": [
    "## Accessing the data\n",
    "\n",
    "- When using 'sets' we can have access to some of the functions from the lists"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "foo = {1,2,34}\n",
    "print(len(foo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n2\n3\n4\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'set' object is not subscriptable",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-5e3ff0aad56f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mitem\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mfoo\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mfoo\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m: 'set' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# We can use a normal 'for' loop to access the data\n",
    "foo = {1,2,3,4}\n",
    "\n",
    "for item in foo:\n",
    "    print(item)\n",
    "foo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "foo = {1,2,3}\n",
    "\n",
    "print(1 in foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 1\n1 2\n2 3\n3 4\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'set' object is not subscriptable",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-27-4f80c751eb24>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mindex\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mitem\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfoo\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mitem\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfoo\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m: 'set' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "foo = {1,2,3,4}\n",
    "\n",
    "# We can use enumerate, but we will not be able to access the items with it\n",
    "for index, item in enumerate(foo):\n",
    "    print(index, item)\n",
    "    \n",
    "print(foo[0])"
   ]
  },
  {
   "source": [
    "## Operations with sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'apple'}\n"
     ]
    }
   ],
   "source": [
    "foo = {'apple', 'banana'}\n",
    "bar = {'orange', 'banana'}\n",
    "\n",
    "# If we want to find the elements that only exist in foo, we can subtract two sets\n",
    "print(foo - bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'orange', 'apple', 'banana'}\n{'orange', 'apple', 'banana'}\n"
     ]
    }
   ],
   "source": [
    "foo = {'apple', 'banana'}\n",
    "bar = {'orange', 'banana'}\n",
    "\n",
    "# If we want to combine the information of two sets we can:\n",
    "\n",
    "# a) do it without changing the original sets\n",
    "new_set = foo.union(bar)\n",
    "print(new_set)\n",
    "\n",
    "# b) update one of the sets:\n",
    "foo.update(bar)\n",
    "print(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'banana'}\n{'banana'}\n"
     ]
    }
   ],
   "source": [
    "# Searching for duplicates is also easy\n",
    "foo = {'apple', 'banana'}\n",
    "bar = {'orange', 'banana'}\n",
    "\n",
    "# a) do it without changing the original sets\n",
    "new_set = foo.intersection(bar)\n",
    "print(new_set)\n",
    "\n",
    "# b) update one of the sets:\n",
    "foo.intersection_update(bar)\n",
    "print(foo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'orange', 'apple'}\n{'orange', 'apple'}\n"
     ]
    }
   ],
   "source": [
    "# We can also search for the non-common elements\n",
    "\n",
    "foo = {'apple', 'banana'}\n",
    "bar = {'orange', 'banana'}\n",
    "\n",
    "# a) do it without changing the original sets\n",
    "new_set = foo.symmetric_difference(bar)\n",
    "print(new_set)\n",
    "\n",
    "# b) update one of the sets:\n",
    "foo.symmetric_difference_update(bar)\n",
    "print(foo)\n"
   ]
  },
  {
   "source": [
    "## Comparing sets \n",
    "\n",
    "It is also possible to check if a given set contains another:\n",
    "\n",
    "- issubset : Returns whether another set contains this set or not\n",
    "- issuperset : Returns whether this set contains another set or not\n",
    "- isdisjoint : Returns whether two sets have a intersection or not (returns True if none of the items are present in both sets)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True True False\n"
     ]
    }
   ],
   "source": [
    "# We can also check if a set \"contains\" or not another one:\n",
    "foo = {1,2,3,4}\n",
    "bar = {i for i in range(10)} \n",
    "\n",
    "print(foo.issubset(bar), bar.issuperset(foo), foo.isdisjoint(bar))"
   ]
  },
  {
   "source": [
    "---\n",
    "# Closer look into functions\n",
    "\n",
    "The functions can be stored in variables and, later on, be called as one would normally do"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<function foo at 0x7f97eaacd0d0> <class 'function'>\n4\n"
     ]
    }
   ],
   "source": [
    "def foo(x,y):\n",
    "    return x + y \n",
    "\n",
    "stored_function = foo \n",
    "print(stored_function, type(stored_function))\n",
    "\n",
    "output  = stored_function(2,2)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "foo - 5\nbar - 6\n"
     ]
    }
   ],
   "source": [
    "# If we want, we can store the functions (as values!) inside a dictionary for  later usage\n",
    "def foo(x,y):\n",
    "    return x + y \n",
    "\n",
    "def bar(x,y):\n",
    "    return x * y \n",
    "\n",
    "stored_functions = {'foo' : foo,\n",
    "                    'bar' : bar\n",
    "                    }\n",
    "\n",
    "for key, func in stored_functions.items():\n",
    "    print(\"{} - {}\".format(key, func(3,2)))"
   ]
  },
  {
   "source": [
    "## Lambda functions\n",
    "\n",
    "They are used to define a function in a single line and \"attribute\" it to a variable \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "foo = lambda x, y: x + y\n",
    "\n",
    "print(foo(2,2))"
   ]
  },
  {
   "source": [
    "## Applying functions to list elements \n",
    "\n",
    "We can use the 'map' function to apply a function to each individul element of the list. It returns an \"iterator\" so, to use the data we must either :\n",
    "\n",
    "- convert it to a list\n",
    "- process it with a loop\n",
    "\n",
    "**NOTE** : after doing, once, either option, the computed result will be lost. For more details on why this happens read about 'iterators' in python:\n",
    "- https://docs.python.org/3/glossary.html#term-iterator\n",
    "- https://www.programiz.com/python-programming/iterator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<map object at 0x7f499ba78580>\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n0\n1\n4\n9\n16\n25\n36\n49\n64\n81\n"
     ]
    }
   ],
   "source": [
    "def bar(x):\n",
    "    return x**2 \n",
    "\n",
    "stored_elems = range(10)\n",
    "\n",
    "\n",
    "result = map(lambda x: x**2, stored_elems) \n",
    "print(result)\n",
    "\n",
    "# a) convert to list: \n",
    "print(list(result))\n",
    "\n",
    "#b) use in a loop:\n",
    "result = map(bar, stored_elems) \n",
    "\n",
    "for entry in result:\n",
    "    print(entry)"
   ]
  },
  {
   "source": [
    "---\n",
    "---\n",
    "# Parallel computation in Python\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Concurrency\n",
    "- Concurrency : A condition that exists when at least two threads are making progress. \n",
    "\n",
    "<img align=\"left\" width=\"500\" src=\"./Figures/schedule.png\">  <br /><br />\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Parallelism\n",
    "\n",
    "- Parallelism : A condition that arises when at least two threads are executing simultaneously.\n",
    "\n",
    "\n",
    "\n",
    "<img align=\"left\" width=\"500\" src=\"./Figures/parallel_scheme.png\">  <br /><br />\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "In the simplest sense, parallel computing is the simultaneous use of multiple compute resources to solve a computational problem:\n",
    "\n",
    "-   A problem is broken into discrete parts that can be solved concurrently\n",
    "-   Each part is further broken down to a series of instructions\n",
    "-   Instructions from each part execute simultaneously on different processors\n",
    "-   An overall control/coordination mechanism is employed\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Why should(n’t) we go parallel ?  - Amdahl's law\n",
    "\n",
    "Parallel computing with many processors is useful only for highly parallelizable programs.\n",
    "\n",
    "\n",
    "<img align=\"left\" width=\"500\" src=\"./Figures/law.png\">  <br /><br />\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## What problems do we face when writting parallel code?\n",
    "\n",
    "- Python does not facilitate writting parallel code, due to the Global Interpreter Lock (GIL)\n",
    "    - Only 1 thread can be executing at any given time.\n",
    "    - Without the GIL python would be significantly slower \n",
    "    \n",
    "- The solution is: launch multiple interpreters at the same time (processes). However:\n",
    "    - Creating new processes is not \"computationally cheap\" \n",
    "    - sharing data between processes can also have a large cost\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---\n",
    "## The basics - Launching the processes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Goodbye\n",
      "hello World\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We create the new processes with the Process function, giving it a target and arguments that we might want to pass\n",
    "\n",
    "After \"starting\" the process, the rest of the Python code will run as usual, even if the process isn't done\n",
    "\n",
    "In this example, even though we started the process, we still the print in the function after the one from the parent process \n",
    "This is a consequence of the method with which the operating system \"schecules\" the operations \n",
    "Thus, when launching processes we do not know, a priori, the order in which the operations will start\n",
    "\"\"\"\n",
    "\n",
    "from multiprocessing import Process\n",
    "\n",
    "def f(name):\n",
    "    print('hello ' + name)\n",
    "\n",
    "\n",
    "p = Process(target=f, args=('World',))\n",
    "p.start()\n",
    "print('Goodbye')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hello World\n",
      "Goodbye\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "However, we can choose to wait for the processes to close before doing anything else, using the 'join' function.\n",
    "\n",
    "By default it will wait until the function is finished. However, we can set a maximum time limit, after which the join() will\n",
    "raise and Exception\n",
    "\n",
    "\"\"\"\n",
    "p = Process(target=f, args=('World',))\n",
    "p.start()\n",
    "p.join()\n",
    "print('Goodbye')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361]\nThe end\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Launching processes one by one can be , most of the time, avoided by using a 'Pool'. \n",
    "\n",
    "- This method chops the data into a number of chunks which it submits to the process pool as separate tasks.\n",
    "- It automatically blocks until everything is processed\n",
    "\"\"\"\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "with Pool(processes=5) as p:\n",
    "    # Unlike the base-python map, this one returns a list, instead of an iteratio\n",
    "    print(p.map(f, range(20)))\n",
    "\n",
    "print(\"The end\")"
   ]
  },
  {
   "source": [
    "---\n",
    "---\n",
    "## The basics - Communication\n",
    "\n",
    "\n",
    "The two methods that we are going to see work in the same way:\n",
    "- We add data to a 'stack' of items\n",
    "- When we request data, it will remove from the stack the oldest item and return it\n",
    "- Also know as FIFO (First In First Out)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Pipes\n",
    "\n",
    "The Pipe() function returns a pair of connection objects connected by a pipe which by default is duplex (two-way). \n",
    "\n",
    "**Notes**: \n",
    "- The data in a pipe may become corrupted if two processes (or threads) try to read from or write to the same end of the pipe at the same time. \n",
    "- There is no risk of corruption from processes using different ends of the pipe at the same time.\n",
    "\n",
    "**Docs:**\n",
    "- https://docs.python.org/3.8/library/multiprocessing.html#connection-objects"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[42, None, 'hello']\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Pipe\n",
    "\n",
    "def f(conn):\n",
    "    conn.send([42, None, 'hello'])\n",
    "\n",
    "parent_conn, child_conn = Pipe()\n",
    "p = Process(target=f, args=(child_conn,))\n",
    "p.start()\n",
    "print(parent_conn.recv())   # will wait until it receives data. If the pipe is empty, it will wait forever\n"
   ]
  },
  {
   "source": [
    "## Queues\n",
    "\n",
    "- Even though pipes faster (as they only have two endpoints), we often want to communicate between a larger number of processes \n",
    "- The interface is slightly diifferent: we use 'put' and 'get'"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[42, None, 'hello']\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def f(q):\n",
    "    q.put([42, None, 'hello'])\n",
    "\n",
    "q = Queue()\n",
    "\n",
    "p = Process(target=f, args=(q,))\n",
    "p.start()\n",
    "print(q.get())    # prints \"[42, None, 'hello']\"\n",
    "p.join()"
   ]
  },
  {
   "source": [
    "## Problems with communication \n",
    "\n",
    "When dealing with larger amounts of data, we can spend more time waiting for data to transfer than we do waiting for our routine. When we are using a queue what happens behind the scenes is:\n",
    "\n",
    "- a) The Python object is serialized (pickled) when it is added\n",
    "- b) The data is de-serialized and the Python object is rebuilt\n",
    "\n",
    "The cost of doing so increases with the amount of data that must be processed. To showcase this, we:\n",
    "- Started by creating an array filled with random numbers, with different sizes\n",
    "- Measuring the time it took to compute the sum of the entire array\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Creating array with size: (170, 9111)\n",
      "\tData Transfer: 0.015794 [s]\n",
      "\tComputing sum: 0.001415 [s]\n",
      "\n",
      "Creating array with size: (500, 9111)\n",
      "\tData Transfer: 0.066358 [s]\n",
      "\tComputing sum: 0.003233 [s]\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "import numpy as np \n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def targ(queue):\n",
    "    t_0 = time.time()\n",
    "    data = queue.get() \n",
    "    print(\"\\tData Transfer: {:.6f} [s]\".format(time.time() - t_0))\n",
    "    \n",
    "    t_0 = time.time()\n",
    "    output = np.sum(data)\n",
    "    print(\"\\tComputing sum: {:.6f} [s]\".format(time.time() - t_0))\n",
    "\n",
    "q = Queue()\n",
    "\n",
    "for size in [(170, 9111), (500, 9111)]:\n",
    "    print(\"\\nCreating array with size: {}\".format(size))\n",
    "    data_in = np.random.random(size)\n",
    "    q.put(data_in)\n",
    "    p = Process(target=targ, args=(q,))\n",
    "    p.start()\n",
    "    p.join()\n"
   ]
  },
  {
   "source": [
    "---\n",
    "\n",
    "## Sharing state between Processes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Synchronization primitives\n",
    "\n",
    "Problems with concurrency:\n",
    "- Concurrency introduces nondeterminism: the exact order in which things are done (the schedule) is not known in advance. \n",
    "- Nondeterminism occurs because the schedule results from the interaction of a system and its scheduling policies with various asynchronous external processes, including physical processes, whose timings are not known or controlled by the system. \n",
    "\n",
    "- The primitives allow to control access to shared resources of the system\n",
    "\n",
    "\n",
    "To understand better how they work, let us look at a scheme for a concurrent setup. We provide a scheme of 3 tasks (with different priorities) being scheduled by a given operating system. With the dashed boxes representing the same shared resource, that cannot be accessed by more than one task, at any given time:\n",
    "\n",
    "<img align=\"left\" width=\"500\" src=\"./Figures/locks.png\">  <br /><br />\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### How it works in Python:\n",
    "- A primitive lock is in one of two states, “locked” or “unlocked”. \n",
    "- Once a process or thread has acquired a lock, subsequent attempts to acquire it from any process or thread will block until it is released\n",
    "\n",
    "We can use:\n",
    "\n",
    "- Locks : Once a process or thread has acquired a lock, subsequent attempts to acquire it from any process or thread will block until it is released; any process or thread may release it. \n",
    "\n",
    "- Semaphores: Allows x number of processe to enter, this can be used for example to limit the number of cpu, io or ram intensive tasks running at the same time."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hello world 0\n",
      "Hello world 1\n",
      "Hello world 2\n",
      "Hello world 3\n",
      "Hello world 4\n",
      "Hello world 5\n",
      "Hello world 6\n",
      "Hello world 7\n",
      "Hello world 8\n",
      "Hello world 9\n",
      "Hello world 10\n",
      "Hello world 11\n",
      "Hello world 12\n",
      "Hello world 13\n",
      "Hello world 14\n",
      "Hello world 15\n",
      "Hello world 16\n",
      "Hello world 17\n",
      "Hello world 18\n",
      "Hello world 19\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "By using the Lock we can control the order in which the processes are able to work\n",
    "\"\"\"\n",
    "\n",
    "from multiprocessing import Process, Lock\n",
    "\n",
    "def f(l, i):\n",
    "    l.acquire()\n",
    "    print('Hello world {}'.format(i))\n",
    "    l.release()\n",
    "\n",
    "lock = Lock()\n",
    "\n",
    "for num in range(20):\n",
    "    p = Process(target=f, args=(lock, num))\n",
    "    p.start()"
   ]
  },
  {
   "source": [
    "## Sharing variables and lists"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.1415927\n[0, -1, -2, -3, -4, -5, -6, -7, -8, -9]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "To check for type codes: https://docs.python.org/3/library/array.html#module-array\n",
    "\"\"\"\n",
    "from multiprocessing import Process, Value, Array\n",
    "\n",
    "def f(n, a):\n",
    "    n.value = 3.1415927\n",
    "    for i in range(len(a)):\n",
    "        a[i] = -a[i]\n",
    "\n",
    "# 'd' -> double\n",
    "num = Value('d', 0.0)\n",
    "arr = Array('i', range(10))\n",
    "\n",
    "p = Process(target=f, args=(num, arr))\n",
    "p.start()\n",
    "p.join()\n",
    "\n",
    "print(num.value)\n",
    "print(arr[:])"
   ]
  },
  {
   "source": [
    "## Sharing numpy arrays\n",
    "\n",
    "By using the shared_memory of python3.8 (or newer) we can:\n",
    "- allocate and manage shared memory, to be accessed by one or more processes \n",
    "- create numpy arrays directly on that memory\n",
    "\n",
    "Docs: https://docs.python.org/3/library/multiprocessing.shared_memory.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Creating the array"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 1 2 3 5 8]\nName: Hello\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import shared_memory\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 1, 2, 3, 5, 8])  # Start with an existing NumPy array\n",
    "\n",
    "shm = shared_memory.SharedMemory(create=True, size=a.nbytes)\n",
    "\n",
    "# Now create a NumPy array backed by shared memory\n",
    "b = np.ndarray(a.shape, dtype=a.dtype, buffer=shm.buf)\n",
    "b[:] = a[:]  # Copy the original data into shared memory\n",
    "print(b)\n",
    "\n",
    "\n",
    "print(\"Name:\", shm.name)  # We did not specify a name so one was chosen for us\n",
    "\n",
    "# At the end we must clean the memory that we were using\n",
    "shm.close()\n",
    "shm.unlink()"
   ]
  },
  {
   "source": [
    "## Accessing the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 1 2 3 5 8]\n",
      "[0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import shared_memory, Process\n",
    "\n",
    "a = np.array([1, 1, 2, 3, 5, 8])  # Start with an existing NumPy array\n",
    "shm = shared_memory.SharedMemory(create=True, size=a.nbytes)\n",
    "# Now create a NumPy array backed by shared memory\n",
    "b = np.ndarray(a.shape, dtype=a.dtype, buffer=shm.buf)\n",
    "b[:] = a[:]  # Copy the original data into shared memory\n",
    "\n",
    "def open_shared_mem(name, size, dtype):\n",
    "    existing_shm = shared_memory.SharedMemory(name=name)\n",
    "    c = np.ndarray(size, dtype=dtype, buffer=existing_shm.buf)\n",
    "    print(\"original data:\", c)\n",
    "    c[:] = 0\n",
    "    existing_shm.close()\n",
    "\n",
    "p = Process(target=open_shared_mem, args=(shm.name, a.shape, a.dtype))\n",
    "p.start()\n",
    "p.join()\n",
    "\n",
    "print(\"Updated array B: \", b)\n",
    "shm.close()\n",
    "shm.unlink()"
   ]
  },
  {
   "source": [
    "## Benchmarking against the Queue\n",
    "\n",
    "\n",
    "existing_shm = shared_memory.SharedMemory(name=name)\n",
    "    c = np.ndarray(size, dtype=dtype, buffer=existing_shm.buf)\n",
    "    "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Creating array with size: (170, 9111)\n",
      "\tShared memory took 0.001792 [s]; Obtained result of 774677.354\n",
      "\tQueue method took: 0.019389 [s]; Obtained result of 774677.354\n",
      "\n",
      "Creating array with size: (500, 9111)\n",
      "\tShared memory took 0.004001 [s]; Obtained result of 2277146.556\n",
      "\tQueue method took: 0.073580 [s]; Obtained result of 2277146.556\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "from multiprocessing import shared_memory, Queue\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def shared_mem_target(name,size, dtype):\n",
    "    t_start = time.time()\n",
    "    existing_shm = shared_memory.SharedMemory(name=name)\n",
    "    c = np.ndarray(size, dtype=dtype, buffer=existing_shm.buf)\n",
    "    output = np.sum(c)\n",
    "    print(\"\\tShared memory took {:.6f} [s]; Obtained result of {:.3f}\".format(time.time() - t_start, output))\n",
    "    existing_shm.close()\n",
    "\n",
    "def queue_target(queue):\n",
    "    t_0 = time.time()\n",
    "    data = queue.get() \n",
    "    output = np.sum(data)\n",
    "    print(\"\\tQueue method took: {:.6f} [s]; Obtained result of {:.3f}\".format(time.time() - t_0, output))\n",
    "\n",
    "\n",
    "q = Queue()\n",
    "\n",
    "for size in [(170, 9111), (500, 9111)]:\n",
    "    print(\"\\nCreating array with size: {}\".format(size))\n",
    "    data_in = np.random.random(size)\n",
    "    \n",
    "    shm = shared_memory.SharedMemory(create=True, size=data_in.nbytes)\n",
    "    b = np.ndarray(data_in.shape, dtype=data_in.dtype, buffer=shm.buf)\n",
    "    b[:] = data_in[:]  \n",
    "\n",
    "    p = Process(target=shared_mem_target, args=(shm.name, size, data_in.dtype))\n",
    "    p.start()\n",
    "    p.join()\n",
    "\n",
    "    q.put(data_in)\n",
    "    p = Process(target=queue_target, args=(q, ))\n",
    "    p.start()\n",
    "    p.join()\n",
    "    shm.close()\n",
    "    shm.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
